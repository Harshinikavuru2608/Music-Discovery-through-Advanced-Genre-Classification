{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e31d781",
   "metadata": {},
   "source": [
    "# LSTM for Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36ac05c",
   "metadata": {},
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "648e59b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/python/3.9-2022.05/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c747b517",
   "metadata": {},
   "source": [
    "## Read the CSV File with Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b07dabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/updated_dataset_with_audio_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a40191",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9401f84e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for missing values:\n",
      "track_id            0\n",
      "name                5\n",
      "artist              5\n",
      "genre               0\n",
      "release_date        0\n",
      "danceability        0\n",
      "energy              0\n",
      "key                 0\n",
      "loudness            0\n",
      "mode                0\n",
      "speechiness         0\n",
      "acousticness        0\n",
      "instrumentalness    0\n",
      "liveness            0\n",
      "valence             0\n",
      "tempo               0\n",
      "time_signature      0\n",
      "duration_ms         0\n",
      "album_cover_url     8\n",
      "bar_count           3\n",
      "beat_count          3\n",
      "tatum_count         3\n",
      "avg_timbre          3\n",
      "avg_pitch           3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nChecking for missing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa67020",
   "metadata": {},
   "source": [
    "### Removed the data with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "523187cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After removing rows with missing values:\n",
      "track_id            0\n",
      "name                5\n",
      "artist              5\n",
      "genre               0\n",
      "release_date        0\n",
      "danceability        0\n",
      "energy              0\n",
      "key                 0\n",
      "loudness            0\n",
      "mode                0\n",
      "speechiness         0\n",
      "acousticness        0\n",
      "instrumentalness    0\n",
      "liveness            0\n",
      "valence             0\n",
      "tempo               0\n",
      "time_signature      0\n",
      "duration_ms         0\n",
      "album_cover_url     8\n",
      "bar_count           0\n",
      "beat_count          0\n",
      "tatum_count         0\n",
      "avg_timbre          0\n",
      "avg_pitch           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "columns_with_nans = ['bar_count', 'beat_count', 'tatum_count', 'avg_timbre', 'avg_pitch']\n",
    "\n",
    "# Dropping rows where any of the specified columns have missing values\n",
    "df = df.dropna(subset=columns_with_nans)\n",
    "\n",
    "# Optionally, you might want to reset the index if you're planning on using the index in future operations\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"\\nAfter removing rows with missing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec0cc75",
   "metadata": {},
   "source": [
    "### Converted (12*1) arrays of 'avg_timbre' and 'avg_pitch' to 12 columns each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a155a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_timbre'] = df['avg_timbre'].apply(ast.literal_eval)\n",
    "df['avg_pitch'] = df['avg_pitch'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3825f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "timbre_columns = [f'timbre_{i}' for i in range(12)]\n",
    "pitch_columns = [f'pitch_{i}' for i in range(12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cefa542",
   "metadata": {},
   "outputs": [],
   "source": [
    "timbre_df = pd.DataFrame(df['avg_timbre'].tolist(), columns=timbre_columns, index=df.index)\n",
    "pitch_df = pd.DataFrame(df['avg_pitch'].tolist(), columns=pitch_columns, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "924f78ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded = pd.concat([df, timbre_df, pitch_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52d1ba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['tempo', 'loudness', 'key', 'time_signature', 'mode', 'bar_count', 'beat_count', 'duration_ms'] + timbre_columns + pitch_columns\n",
    "targets = ['danceability', 'energy', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f0c45d",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73e0257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_expanded[features], df_expanded[targets], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0e5e8bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6365</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.0739</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      danceability  energy  speechiness  acousticness  instrumentalness  \\\n",
       "6365          0.46   0.497       0.0739         0.544               0.0   \n",
       "\n",
       "      liveness  valence  \n",
       "6365     0.226    0.554  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bb7b49",
   "metadata": {},
   "source": [
    "## Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56600a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22d08d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Assuming your scaler is named \"scaler\" and has been fitted to your training data\n",
    "dump(scaler, 'scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5677ab99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6563231 , 0.74338812, 0.18181818, ..., 0.51534161, 0.28900405,\n",
       "        0.34488467],\n",
       "       [0.58161231, 0.86800602, 0.36363636, ..., 0.67648396, 0.30171423,\n",
       "        0.41005285],\n",
       "       [0.60894586, 0.86031985, 0.09090909, ..., 0.26462613, 0.33490822,\n",
       "        0.2497152 ],\n",
       "       ...,\n",
       "       [0.71773501, 0.85837062, 1.        , ..., 0.3023889 , 0.23673143,\n",
       "        0.41798922],\n",
       "       [0.4330537 , 0.59318655, 0.36363636, ..., 0.23625334, 0.18112224,\n",
       "        0.37133918],\n",
       "       [0.44251007, 0.66526381, 0.        , ..., 0.15796592, 0.21753203,\n",
       "        0.23373458]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70459769",
   "metadata": {},
   "source": [
    "## Building the Model and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a866ec41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 18:55:52.395371: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-20 18:56:00.123797: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-20 18:56:06.747060: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ecaec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbe9bcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir/intro_to_kt/tuner0.json\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first LSTM layer is 192,\n",
      "and the optimal dropout rate in the first LSTM layer is 0.1.\n",
      "\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the second LSTM layer is 416,\n",
      "and the optimal dropout rate in the first LSTM layer is 0.0.\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 118ms/step - loss: 0.0790 - mae: 0.2024 - val_loss: 0.0316 - val_mae: 0.1300\n",
      "Epoch 2/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 107ms/step - loss: 0.0305 - mae: 0.1261 - val_loss: 0.0248 - val_mae: 0.1141\n",
      "Epoch 3/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 109ms/step - loss: 0.0251 - mae: 0.1136 - val_loss: 0.0243 - val_mae: 0.1132\n",
      "Epoch 4/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 107ms/step - loss: 0.0241 - mae: 0.1111 - val_loss: 0.0231 - val_mae: 0.1043\n",
      "Epoch 5/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 107ms/step - loss: 0.0236 - mae: 0.1086 - val_loss: 0.0228 - val_mae: 0.1049\n",
      "Epoch 6/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 109ms/step - loss: 0.0232 - mae: 0.1077 - val_loss: 0.0217 - val_mae: 0.1033\n",
      "Epoch 7/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - loss: 0.0219 - mae: 0.1047 - val_loss: 0.0217 - val_mae: 0.1021\n",
      "Epoch 8/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 111ms/step - loss: 0.0218 - mae: 0.1040 - val_loss: 0.0208 - val_mae: 0.0996\n",
      "Epoch 9/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 107ms/step - loss: 0.0217 - mae: 0.1034 - val_loss: 0.0213 - val_mae: 0.0999\n",
      "Epoch 10/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 108ms/step - loss: 0.0213 - mae: 0.1027 - val_loss: 0.0205 - val_mae: 0.1007\n",
      "Epoch 11/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - loss: 0.0206 - mae: 0.1010 - val_loss: 0.0202 - val_mae: 0.0976\n",
      "Epoch 12/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - loss: 0.0204 - mae: 0.0999 - val_loss: 0.0201 - val_mae: 0.0994\n",
      "Epoch 13/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 109ms/step - loss: 0.0211 - mae: 0.1016 - val_loss: 0.0202 - val_mae: 0.0985\n",
      "Epoch 14/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 108ms/step - loss: 0.0200 - mae: 0.0986 - val_loss: 0.0202 - val_mae: 0.0967\n",
      "Epoch 15/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - loss: 0.0201 - mae: 0.0980 - val_loss: 0.0192 - val_mae: 0.0952\n",
      "Epoch 16/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 104ms/step - loss: 0.0193 - mae: 0.0963 - val_loss: 0.0198 - val_mae: 0.0928\n",
      "Epoch 17/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 109ms/step - loss: 0.0193 - mae: 0.0960 - val_loss: 0.0202 - val_mae: 0.0926\n",
      "Epoch 18/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - loss: 0.0192 - mae: 0.0956 - val_loss: 0.0190 - val_mae: 0.0930\n",
      "Epoch 19/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 109ms/step - loss: 0.0190 - mae: 0.0944 - val_loss: 0.0192 - val_mae: 0.0924\n",
      "Epoch 20/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 108ms/step - loss: 0.0188 - mae: 0.0936 - val_loss: 0.0191 - val_mae: 0.0902\n",
      "Epoch 21/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - loss: 0.0189 - mae: 0.0933 - val_loss: 0.0194 - val_mae: 0.0926\n",
      "Epoch 22/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 105ms/step - loss: 0.0180 - mae: 0.0908 - val_loss: 0.0194 - val_mae: 0.0956\n",
      "Epoch 23/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 109ms/step - loss: 0.0184 - mae: 0.0915 - val_loss: 0.0187 - val_mae: 0.0896\n",
      "Epoch 24/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - loss: 0.0181 - mae: 0.0907 - val_loss: 0.0188 - val_mae: 0.0911\n",
      "Epoch 25/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 108ms/step - loss: 0.0176 - mae: 0.0896 - val_loss: 0.0184 - val_mae: 0.0888\n",
      "Epoch 26/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 109ms/step - loss: 0.0181 - mae: 0.0897 - val_loss: 0.0188 - val_mae: 0.0919\n",
      "Epoch 27/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 107ms/step - loss: 0.0179 - mae: 0.0899 - val_loss: 0.0180 - val_mae: 0.0882\n",
      "Epoch 28/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 104ms/step - loss: 0.0173 - mae: 0.0878 - val_loss: 0.0184 - val_mae: 0.0887\n",
      "Epoch 29/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 105ms/step - loss: 0.0170 - mae: 0.0868 - val_loss: 0.0175 - val_mae: 0.0859\n",
      "Epoch 30/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - loss: 0.0175 - mae: 0.0877 - val_loss: 0.0174 - val_mae: 0.0871\n",
      "Epoch 31/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - loss: 0.0175 - mae: 0.0875 - val_loss: 0.0180 - val_mae: 0.0891\n",
      "Epoch 32/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 108ms/step - loss: 0.0169 - mae: 0.0862 - val_loss: 0.0180 - val_mae: 0.0871\n",
      "Epoch 33/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 105ms/step - loss: 0.0171 - mae: 0.0859 - val_loss: 0.0185 - val_mae: 0.0893\n",
      "Epoch 34/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 104ms/step - loss: 0.0166 - mae: 0.0855 - val_loss: 0.0178 - val_mae: 0.0859\n",
      "Epoch 35/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 108ms/step - loss: 0.0169 - mae: 0.0856 - val_loss: 0.0178 - val_mae: 0.0862\n",
      "Epoch 36/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 109ms/step - loss: 0.0171 - mae: 0.0867 - val_loss: 0.0172 - val_mae: 0.0840\n",
      "Epoch 37/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 105ms/step - loss: 0.0165 - mae: 0.0849 - val_loss: 0.0173 - val_mae: 0.0851\n",
      "Epoch 38/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 105ms/step - loss: 0.0163 - mae: 0.0842 - val_loss: 0.0172 - val_mae: 0.0852\n",
      "Epoch 39/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 108ms/step - loss: 0.0170 - mae: 0.0859 - val_loss: 0.0170 - val_mae: 0.0837\n",
      "Epoch 40/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 109ms/step - loss: 0.0161 - mae: 0.0837 - val_loss: 0.0179 - val_mae: 0.0860\n",
      "Epoch 41/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 105ms/step - loss: 0.0170 - mae: 0.0860 - val_loss: 0.0178 - val_mae: 0.0857\n",
      "Epoch 42/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - loss: 0.0162 - mae: 0.0831 - val_loss: 0.0171 - val_mae: 0.0825\n",
      "Epoch 43/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 108ms/step - loss: 0.0156 - mae: 0.0829 - val_loss: 0.0169 - val_mae: 0.0836\n",
      "Epoch 44/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 104ms/step - loss: 0.0160 - mae: 0.0826 - val_loss: 0.0184 - val_mae: 0.0874\n",
      "Epoch 45/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 105ms/step - loss: 0.0163 - mae: 0.0839 - val_loss: 0.0171 - val_mae: 0.0853\n",
      "Epoch 46/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - loss: 0.0161 - mae: 0.0836 - val_loss: 0.0180 - val_mae: 0.0872\n",
      "Epoch 47/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 109ms/step - loss: 0.0162 - mae: 0.0838 - val_loss: 0.0169 - val_mae: 0.0834\n",
      "Epoch 48/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 107ms/step - loss: 0.0157 - mae: 0.0820 - val_loss: 0.0180 - val_mae: 0.0864\n",
      "Epoch 49/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 110ms/step - loss: 0.0163 - mae: 0.0829 - val_loss: 0.0175 - val_mae: 0.0849\n",
      "Epoch 50/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - loss: 0.0157 - mae: 0.0821 - val_loss: 0.0166 - val_mae: 0.0830\n",
      "Epoch 51/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 111ms/step - loss: 0.0155 - mae: 0.0813 - val_loss: 0.0170 - val_mae: 0.0821\n",
      "Epoch 52/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 111ms/step - loss: 0.0156 - mae: 0.0821 - val_loss: 0.0164 - val_mae: 0.0807\n",
      "Epoch 53/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 107ms/step - loss: 0.0154 - mae: 0.0807 - val_loss: 0.0164 - val_mae: 0.0824\n",
      "Epoch 54/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 109ms/step - loss: 0.0154 - mae: 0.0812 - val_loss: 0.0167 - val_mae: 0.0814\n",
      "Epoch 55/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 107ms/step - loss: 0.0158 - mae: 0.0817 - val_loss: 0.0170 - val_mae: 0.0842\n",
      "Epoch 56/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 110ms/step - loss: 0.0146 - mae: 0.0794 - val_loss: 0.0168 - val_mae: 0.0860\n",
      "Epoch 57/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 108ms/step - loss: 0.0154 - mae: 0.0819 - val_loss: 0.0167 - val_mae: 0.0824\n",
      "Epoch 58/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 109ms/step - loss: 0.0155 - mae: 0.0813 - val_loss: 0.0171 - val_mae: 0.0833\n",
      "Epoch 59/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 109ms/step - loss: 0.0151 - mae: 0.0802 - val_loss: 0.0161 - val_mae: 0.0797\n",
      "Epoch 60/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 112ms/step - loss: 0.0147 - mae: 0.0790 - val_loss: 0.0164 - val_mae: 0.0819\n",
      "Epoch 61/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 108ms/step - loss: 0.0151 - mae: 0.0804 - val_loss: 0.0166 - val_mae: 0.0817\n",
      "Epoch 62/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 109ms/step - loss: 0.0154 - mae: 0.0809 - val_loss: 0.0163 - val_mae: 0.0807\n",
      "Epoch 63/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 108ms/step - loss: 0.0149 - mae: 0.0806 - val_loss: 0.0159 - val_mae: 0.0809\n",
      "Epoch 64/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 105ms/step - loss: 0.0148 - mae: 0.0796 - val_loss: 0.0161 - val_mae: 0.0815\n",
      "Epoch 65/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 105ms/step - loss: 0.0152 - mae: 0.0804 - val_loss: 0.0161 - val_mae: 0.0802\n",
      "Epoch 66/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 104ms/step - loss: 0.0149 - mae: 0.0793 - val_loss: 0.0163 - val_mae: 0.0820\n",
      "Epoch 67/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - loss: 0.0153 - mae: 0.0810 - val_loss: 0.0162 - val_mae: 0.0799\n",
      "Epoch 68/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - loss: 0.0145 - mae: 0.0786 - val_loss: 0.0166 - val_mae: 0.0820\n",
      "Epoch 69/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 110ms/step - loss: 0.0144 - mae: 0.0787 - val_loss: 0.0167 - val_mae: 0.0844\n",
      "Epoch 70/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 104ms/step - loss: 0.0145 - mae: 0.0792 - val_loss: 0.0159 - val_mae: 0.0803\n",
      "Epoch 71/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - loss: 0.0147 - mae: 0.0787 - val_loss: 0.0159 - val_mae: 0.0790\n",
      "Epoch 72/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 108ms/step - loss: 0.0149 - mae: 0.0788 - val_loss: 0.0166 - val_mae: 0.0825\n",
      "Epoch 73/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - loss: 0.0148 - mae: 0.0790 - val_loss: 0.0159 - val_mae: 0.0811\n",
      "Epoch 74/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 104ms/step - loss: 0.0143 - mae: 0.0780 - val_loss: 0.0164 - val_mae: 0.0822\n",
      "Epoch 75/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 105ms/step - loss: 0.0141 - mae: 0.0773 - val_loss: 0.0158 - val_mae: 0.0804\n",
      "Epoch 76/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 104ms/step - loss: 0.0137 - mae: 0.0765 - val_loss: 0.0158 - val_mae: 0.0792\n",
      "Epoch 77/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 105ms/step - loss: 0.0147 - mae: 0.0787 - val_loss: 0.0157 - val_mae: 0.0782\n",
      "Epoch 78/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 104ms/step - loss: 0.0138 - mae: 0.0768 - val_loss: 0.0159 - val_mae: 0.0797\n",
      "Epoch 79/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 104ms/step - loss: 0.0136 - mae: 0.0762 - val_loss: 0.0161 - val_mae: 0.0797\n",
      "Epoch 80/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 109ms/step - loss: 0.0140 - mae: 0.0763 - val_loss: 0.0158 - val_mae: 0.0801\n",
      "Epoch 81/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 103ms/step - loss: 0.0143 - mae: 0.0783 - val_loss: 0.0163 - val_mae: 0.0821\n",
      "Epoch 82/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 105ms/step - loss: 0.0144 - mae: 0.0780 - val_loss: 0.0160 - val_mae: 0.0813\n",
      "Epoch 83/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - loss: 0.0139 - mae: 0.0770 - val_loss: 0.0158 - val_mae: 0.0804\n",
      "Epoch 84/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 104ms/step - loss: 0.0141 - mae: 0.0770 - val_loss: 0.0164 - val_mae: 0.0830\n",
      "Epoch 85/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 104ms/step - loss: 0.0136 - mae: 0.0761 - val_loss: 0.0159 - val_mae: 0.0807\n",
      "Epoch 86/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 104ms/step - loss: 0.0138 - mae: 0.0765 - val_loss: 0.0172 - val_mae: 0.0834\n",
      "Epoch 87/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 108ms/step - loss: 0.0140 - mae: 0.0769 - val_loss: 0.0157 - val_mae: 0.0810\n",
      "Epoch 88/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 104ms/step - loss: 0.0136 - mae: 0.0761 - val_loss: 0.0163 - val_mae: 0.0795\n",
      "Epoch 89/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 104ms/step - loss: 0.0134 - mae: 0.0755 - val_loss: 0.0162 - val_mae: 0.0816\n",
      "Epoch 90/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 104ms/step - loss: 0.0138 - mae: 0.0768 - val_loss: 0.0157 - val_mae: 0.0815\n",
      "Epoch 91/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - loss: 0.0137 - mae: 0.0766 - val_loss: 0.0157 - val_mae: 0.0794\n",
      "Epoch 92/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 104ms/step - loss: 0.0130 - mae: 0.0745 - val_loss: 0.0175 - val_mae: 0.0847\n",
      "Epoch 93/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 105ms/step - loss: 0.0138 - mae: 0.0765 - val_loss: 0.0158 - val_mae: 0.0814\n",
      "Epoch 94/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - loss: 0.0138 - mae: 0.0767 - val_loss: 0.0162 - val_mae: 0.0826\n",
      "Epoch 95/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - loss: 0.0134 - mae: 0.0754 - val_loss: 0.0158 - val_mae: 0.0800\n",
      "Epoch 96/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 104ms/step - loss: 0.0136 - mae: 0.0761 - val_loss: 0.0158 - val_mae: 0.0807\n",
      "Epoch 97/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - loss: 0.0131 - mae: 0.0745 - val_loss: 0.0157 - val_mae: 0.0789\n",
      "Epoch 98/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 103ms/step - loss: 0.0127 - mae: 0.0740 - val_loss: 0.0161 - val_mae: 0.0809\n",
      "Epoch 99/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 103ms/step - loss: 0.0132 - mae: 0.0751 - val_loss: 0.0157 - val_mae: 0.0790\n",
      "Epoch 100/100\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 107ms/step - loss: 0.0132 - mae: 0.0753 - val_loss: 0.0160 - val_mae: 0.0806\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Define hyperparameter search space\n",
    "    model.add(LSTM(units=hp.Int('units', min_value=32, max_value=512, step=32),\n",
    "                   input_shape=(1,X_train_scaled.shape[1]),\n",
    "                   return_sequences=True))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_1', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    # Optionally adding a second LSTM layer\n",
    "    if hp.Boolean('second_lstm_layer'):\n",
    "        model.add(LSTM(units=hp.Int('units_l2', min_value=32, max_value=512, step=32), return_sequences=False))\n",
    "        model.add(Dropout(rate=hp.Float('dropout_2', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    else:\n",
    "        model.add(LSTM(units=hp.Int('units_l2', min_value=32, max_value=512, step=32)))\n",
    "    \n",
    "    model.add(Dense(7))  # Output layer for the 7 target variables\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create a tuner\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=10,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')\n",
    "\n",
    "# Create a callback to stop training early after reaching a certain value for the validation loss\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Execute the hyperparameter search\n",
    "tuner.search(X_train_reshaped, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first LSTM layer is {best_hps.get('units')},\n",
    "and the optimal dropout rate in the first LSTM layer is {best_hps.get('dropout_1')}.\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the second LSTM layer is {best_hps.get('units_l2')},\n",
    "and the optimal dropout rate in the first LSTM layer is {best_hps.get('dropout_2')}.\n",
    "\"\"\")\n",
    "\n",
    "# Build the model with the optimal hyperparameters and train it on the data\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train_reshaped, y_train, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348f1041",
   "metadata": {},
   "source": [
    "## Making Prediction on Test Data and Calculating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ddf59c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64d7ef0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test_reshaped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "725a07f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for danceability: 0.007122517971619974\n",
      "MSE for energy: 0.004722989208851494\n",
      "MSE for speechiness: 0.0029597603693015443\n",
      "MSE for acousticness: 0.007257743931439267\n",
      "MSE for instrumentalness: 0.03806349811535897\n",
      "MSE for liveness: 0.02460997063143774\n",
      "MSE for valence: 0.02603261554741383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Ensure predictions and y_total are in the same format\n",
    "# If y_total is a DataFrame, you might need to convert predictions to DataFrame or vice versa\n",
    "predictions_df = pd.DataFrame(predictions, columns=y_test.columns)\n",
    "\n",
    "# Calculate MSE for each target variable\n",
    "for column in y_test.columns:\n",
    "    mse = mean_squared_error(y_test[column], predictions_df[column])\n",
    "    print(f'MSE for {column}: {mse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ffd0f3",
   "metadata": {},
   "source": [
    "## Saving the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cfea60f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "94ed48b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('RNN_LSTM_audiofeatures.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (Conda 2022.05) [python/3.9-2022.05]",
   "language": "python",
   "name": "python39_202205"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
